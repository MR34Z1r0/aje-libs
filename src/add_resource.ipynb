{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b966b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml==4.9.2\n",
      "  Downloading lxml-4.9.2-cp39-cp39-win_amd64.whl (3.9 MB)\n",
      "     ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.9 MB 991.0 kB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.2/3.9 MB 2.1 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.3/3.9 MB 2.5 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 0.5/3.9 MB 2.9 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.7/3.9 MB 2.9 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 0.8/3.9 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 1.0/3.9 MB 3.1 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 1.2/3.9 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 1.3/3.9 MB 3.2 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 1.5/3.9 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 1.6/3.9 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 1.8/3.9 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 1.9/3.9 MB 3.3 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 2.1/3.9 MB 3.3 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 2.3/3.9 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 2.5/3.9 MB 3.4 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 2.7/3.9 MB 3.4 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 2.8/3.9 MB 3.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 3.0/3.9 MB 3.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 3.1/3.9 MB 3.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 3.1/3.9 MB 3.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 3.1/3.9 MB 3.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 3.3/3.9 MB 3.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 3.4/3.9 MB 3.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 3.6/3.9 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.8/3.9 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.9/3.9 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.9/3.9 MB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 6.0.0\n",
      "    Uninstalling lxml-6.0.0:\n",
      "      Successfully uninstalled lxml-6.0.0\n",
      "Successfully installed lxml-4.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx>=0.8.11 \n",
    "!pip install python-pptx>=0.6.21 \n",
    "!pip install openpyxl>=3.1.0 \n",
    "!pip install PyPDF2>=3.0.0 \n",
    "!pip install lxml==4.9.2\n",
    "!pip install pinecone>=2.2.0\n",
    "!pip install requests>=2.31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d08ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\":\"INFO\",\"location\":\"__init__:22\",\"message\":\"Inicializando SSMParameterHelper para el parámetro: /dev/agent-resources/chatbot\",\"timestamp\":\"2025-07-01 13:22:51,432-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"get_parameter_value:32\",\"message\":\"Intentando obtener el parámetro: /dev/agent-resources/chatbot\",\"timestamp\":\"2025-07-01 13:22:51,434-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"get_parameter_value:40\",\"message\":\"Parámetro obtenido con éxito: /dev/agent-resources/chatbot\",\"timestamp\":\"2025-07-01 13:22:52,028-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"__init__:23\",\"message\":\"Inicializando SecretsHelper para el secreto: dev/agent-resources/pinecone-api-key\",\"timestamp\":\"2025-07-01 13:22:52,062-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"get_secret_value:31\",\"message\":\"Intentando obtener el secreto: dev/agent-resources/pinecone-api-key\",\"timestamp\":\"2025-07-01 13:22:52,063-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"get_secret_value:35\",\"message\":\"Secreto obtenido con éxito: dev/agent-resources/pinecone-api-key\",\"timestamp\":\"2025-07-01 13:22:52,885-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"get_secret_value:43\",\"message\":\"Retornando valor para la clave específica: PINECONE_INDEX_NAME\",\"timestamp\":\"2025-07-01 13:22:52,887-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"get_secret_value:31\",\"message\":\"Intentando obtener el secreto: dev/agent-resources/pinecone-api-key\",\"timestamp\":\"2025-07-01 13:22:52,889-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"get_secret_value:35\",\"message\":\"Secreto obtenido con éxito: dev/agent-resources/pinecone-api-key\",\"timestamp\":\"2025-07-01 13:22:53,039-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"get_secret_value:43\",\"message\":\"Retornando valor para la clave específica: PINECONE_API_KEY\",\"timestamp\":\"2025-07-01 13:22:53,040-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"__init__:34\",\"message\":\"Configured helper for S3 bucket: upeu-509399624591-us-east-1-dev-agent-resources-resources-s3\",\"timestamp\":\"2025-07-01 13:22:54,468-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"__init__:37\",\"message\":\"Configured helper for DynamoDB table: upeu-dev-agent-resources-learning_resources-ddb\",\"timestamp\":\"2025-07-01 13:22:55,169-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"__init__:37\",\"message\":\"Configured helper for DynamoDB table: upeu-dev-agent-resources-learning_resources_hash-ddb\",\"timestamp\":\"2025-07-01 13:22:55,596-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"_validate_index:54\",\"message\":\"Successfully connected to Pinecone index: resources-knowledge\",\"timestamp\":\"2025-07-01 13:22:59,934-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n",
      "{\"level\":\"INFO\",\"location\":\"__init__:48\",\"message\":\"Configured helper for Pinecone serverless index: resources-knowledge\",\"timestamp\":\"2025-07-01 13:22:59,935-0500\",\"service\":\"service_undefined\",\"name\":\"aje_libs.common.helpers.s3_helper\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "import requests\n",
    "import unicodedata\n",
    "import re\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "from uuid import uuid4\n",
    "\n",
    "# Importar helpers de aje-libs\n",
    "from aje_libs.common.helpers.s3_helper import S3Helper\n",
    "from aje_libs.common.helpers.dynamodb_helper import DynamoDBHelper\n",
    "from aje_libs.bd.helpers.pinecone_helper import PineconeHelper\n",
    "from aje_libs.documents.helpers.document_processor import DocumentProcessor\n",
    "from aje_libs.common.logger import custom_logger\n",
    "from aje_libs.common.helpers.secrets_helper import SecretsHelper\n",
    "from aje_libs.common.helpers.ssm_helper import SSMParameterHelper\n",
    "\n",
    "boto3.setup_default_session(profile_name='prd-upeu-admin')\n",
    "\n",
    "# Configuración\n",
    "ENVIRONMENT = 'dev'#os.environ[\"ENVIRONMENT\"]\n",
    "PROJECT_NAME = 'agent-resources'#os.environ[\"PROJECT_NAME\"]\n",
    "OWNER = 'Miguel Espinoza'#os.environ[\"OWNER\"]\n",
    "DYNAMO_RESOURCES_TABLE = 'upeu-dev-agent-resources-learning_resources-ddb'#os.environ[\"DYNAMO_RESOURCES_TABLE\"]\n",
    "DYNAMO_RESOURCES_HASH_TABLE = 'upeu-dev-agent-resources-learning_resources_hash-ddb'#os.environ[\"DYNAMO_RESOURCES_HASH_TABLE\"]\n",
    "S3_RESOURCES_BUCKET = 'upeu-509399624591-us-east-1-dev-agent-resources-resources-s3'#os.environ[\"S3_RESOURCES_BUCKET\"]\n",
    "\n",
    "# Parameter Store\n",
    "ssm_chatbot = SSMParameterHelper(f\"/{ENVIRONMENT}/{PROJECT_NAME}/chatbot\")\n",
    "PARAMETER_VALUE = json.loads(ssm_chatbot.get_parameter_value())\n",
    "\n",
    "EMBEDDINGS_MODEL_ID = PARAMETER_VALUE[\"EMBEDDINGS_MODEL_ID\"]\n",
    "EMBEDDINGS_REGION = PARAMETER_VALUE[\"EMBEDDINGS_REGION\"]\n",
    "# Secrets\n",
    "secret_pinecone = SecretsHelper(f\"{ENVIRONMENT}/{PROJECT_NAME}/pinecone-api-key\")\n",
    "\n",
    "PINECONE_INDEX_NAME = secret_pinecone.get_secret_value(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_API_KEY = secret_pinecone.get_secret_value(\"PINECONE_API_KEY\")\n",
    "\n",
    "DOWNLOAD_FOLDER = \"/tmp/downloads\"\n",
    "S3_PATH = \"SOFIA_FILE/PLANIFICACION/AV_Recursos\"\n",
    " \n",
    "logger = custom_logger(__name__, owner=OWNER, service=PROJECT_NAME)\n",
    "\n",
    "# Crear helper instances\n",
    "s3_helper = S3Helper(bucket_name=S3_RESOURCES_BUCKET)\n",
    "files_table_helper = DynamoDBHelper(\n",
    "    table_name=DYNAMO_RESOURCES_TABLE,\n",
    "    pk_name=\"resource_id\"\n",
    ")\n",
    "hash_table_helper = DynamoDBHelper(\n",
    "    table_name=DYNAMO_RESOURCES_HASH_TABLE,\n",
    "    pk_name=\"file_hash\"\n",
    ")\n",
    "pinecone_helper = PineconeHelper(\n",
    "    index_name=PINECONE_INDEX_NAME,\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    embeddings_model_id=EMBEDDINGS_MODEL_ID,\n",
    "    embeddings_region=EMBEDDINGS_REGION\n",
    ")\n",
    "document_processor = DocumentProcessor()\n",
    "\n",
    "def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Handler principal de Lambda para agregar un recurso educativo.\n",
    "    \n",
    "    :param event: Evento de Lambda (debe contener body con resourceId, content.title, content.driveId)\n",
    "    :param context: Contexto de Lambda\n",
    "    :return: Respuesta estandarizada\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parsear el body del evento\n",
    "        if 'body' in event:\n",
    "            if isinstance(event['body'], dict):\n",
    "                body = event['body']\n",
    "            else:\n",
    "                body = json.loads(event['body'])\n",
    "        else:\n",
    "            body = event\n",
    "        \n",
    "        # Validar que los campos necesarios estén presentes usando el formato estandarizado\n",
    "        required_fields = [\"RecursoDidacticoId\", \"DriveId\", \"TituloRecurso\", \"SilaboEventoId\"]\n",
    "        missing_fields = [field for field in required_fields if field not in body]\n",
    "        \n",
    "        if missing_fields:\n",
    "            logger.error(f\"Campos requeridos faltantes: {missing_fields}\")        \n",
    "            return {\n",
    "                \"statusCode\": 400,\n",
    "                \"body\": json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"message\": f\"Campos requeridos faltantes: {missing_fields}\"\n",
    "                    })\n",
    "                }\n",
    "        \n",
    "        resource_id = body[\"RecursoDidacticoId\"]\n",
    "        title = body[\"TituloRecurso\"]\n",
    "        drive_id = body[\"DriveId\"]\n",
    "        \n",
    "        # Procesar el recurso\n",
    "        result = process_resource_addition(resource_id, title, drive_id)\n",
    "        \n",
    "        if result['success']:\n",
    "            return {            \n",
    "                \"statusCode\": 200,\n",
    "                \"body\": json.dumps({\n",
    "                    \"success\": True,\n",
    "                    \"data\": {\n",
    "                    \"resourceId\": resource_id\n",
    "                    }\n",
    "                })\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"statusCode\": 500,\n",
    "                \"body\": json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"message\": result['message']\n",
    "                })\n",
    "            }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in lambda_handler: {str(e)}\", exc_info=True)\n",
    "        return {\n",
    "            \"statusCode\": 500,\n",
    "            \"body\": json.dumps({\n",
    "                \"success\": False,\n",
    "                \"message\": str(e)\n",
    "            })\n",
    "        }\n",
    "\n",
    "def process_resource_addition(resource_id: str, title: str, drive_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Procesa la adición de un recurso educativo.\n",
    "    \n",
    "    :param resource_id: ID del recurso\n",
    "    :param title: Título del recurso\n",
    "    :param drive_id: ID de Google Drive\n",
    "    :return: Resultado de la operación\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Descargar archivo desde Google Drive\n",
    "        file_path = download_file_from_gdrive(title, drive_id)\n",
    "        \n",
    "        # Generar hash del archivo\n",
    "        file_hash = generate_file_hash(file_path)\n",
    "        \n",
    "        # Verificar si el hash ya existe en DynamoDB\n",
    "        existing_hash = hash_table_helper.get_item(file_hash)\n",
    "        if existing_hash:\n",
    "            logger.info(f\"Hash {file_hash} already exists in DynamoDB\")\n",
    "            os.remove(file_path)  # Limpiar archivo temporal\n",
    "            return {'success': False, 'message': 'Resource already exists'}\n",
    "        \n",
    "        # Subir archivo a S3\n",
    "        object_key = f\"{S3_PATH}/{sanitize_filename(title)}\"\n",
    "        s3_path = s3_helper.upload_file(file_path, object_key)\n",
    "        \n",
    "        # Registrar en DynamoDB\n",
    "        resource_data = {\n",
    "            'resource_id': resource_id,\n",
    "            'resource_title': title,\n",
    "            'drive_id': drive_id,\n",
    "            'file_hash': file_hash,\n",
    "            's3_path': s3_path,\n",
    "            'pinecone_ids': []\n",
    "        }\n",
    "        \n",
    "        # Procesar el documento y obtener los IDs de Pinecone\n",
    "        pinecone_ids = process_document_to_pinecone(file_path, resource_data)\n",
    "        \n",
    "        # Actualizar los IDs de Pinecone en el recurso\n",
    "        resource_data['pinecone_ids'] = pinecone_ids\n",
    "        \n",
    "        # Guardar en DynamoDB\n",
    "        files_table_helper.put_item(resource_data)\n",
    "        hash_table_helper.put_item({\n",
    "            'file_hash': file_hash,\n",
    "            's3_path': s3_path\n",
    "        })\n",
    "        \n",
    "        # Limpiar archivo temporal\n",
    "        os.remove(file_path)\n",
    "        \n",
    "        logger.info(f\"Successfully added resource {resource_id}\")\n",
    "        return {'success': True, 'message': 'Resource added successfully'}\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing resource addition: {str(e)}\", exc_info=True)\n",
    "        return {'success': False, 'message': str(e)}\n",
    "\n",
    "def download_file_from_gdrive(file_name: str, gdrive_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Descarga un archivo desde Google Drive y lo guarda localmente.\n",
    "    \n",
    "    :param file_name: Nombre del archivo\n",
    "    :param gdrive_id: ID de Google Drive\n",
    "    :return: Ruta del archivo descargado\n",
    "    \"\"\"\n",
    "    url = f\"https://drive.google.com/uc?export=download&id={gdrive_id}\"\n",
    "    file_path = os.path.join(DOWNLOAD_FOLDER, file_name)\n",
    "    \n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)\n",
    "    \n",
    "    logger.info(f\"Downloading {file_name} from Google Drive\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with open(file_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "def generate_file_hash(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Genera un hash SHA256 para el archivo dado.\n",
    "    \n",
    "    :param file_path: Ruta al archivo\n",
    "    :return: Hash SHA256\n",
    "    \"\"\"\n",
    "    logger.info(\"Generating file hash\")\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    \n",
    "    with open(file_path, 'rb') as f:\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(byte_block)\n",
    "    \n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "def sanitize_filename(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Limpia caracteres especiales y espacios en el nombre del archivo.\n",
    "    \n",
    "    :param filename: Nombre original del archivo\n",
    "    :return: Nombre sanitizado\n",
    "    \"\"\"\n",
    "    normalized_name = unicodedata.normalize('NFKD', filename.lower()).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    return re.sub(r\"[., ]\", \"_\", normalized_name)\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 400, overlap: int = 20) -> List[str]:\n",
    "    \"\"\"\n",
    "    Divide el texto en chunks con solapamiento.\n",
    "    \n",
    "    :param text: Texto a dividir\n",
    "    :param chunk_size: Tamaño de cada chunk\n",
    "    :param overlap: Solapamiento entre chunks\n",
    "    :return: Lista de chunks\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    words = text.split()\n",
    "    \n",
    "    if not words:\n",
    "        return []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        # Calcular el final del chunk actual\n",
    "        end = min(i + chunk_size, len(words))\n",
    "        \n",
    "        # Crear el chunk\n",
    "        chunk = \" \".join(words[i:end])\n",
    "        chunks.append(chunk)\n",
    "        \n",
    "        # Avanzar, teniendo en cuenta el solapamiento\n",
    "        i += (chunk_size - overlap)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def process_document_to_pinecone(file_path: str, metadata: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Procesa un documento y lo indexa en Pinecone.\n",
    "    \n",
    "    :param file_path: Ruta al archivo\n",
    "    :param metadata: Metadatos del documento\n",
    "    :return: Lista de IDs de Pinecone\n",
    "    \"\"\"\n",
    "    file_extension = Path(file_path).suffix.lower().replace('.', '')\n",
    "    \n",
    "    try:\n",
    "        # Extraer texto del documento usando DocumentProcessor\n",
    "        text_content = document_processor.process_document(file_path)\n",
    "        \n",
    "        if not text_content:\n",
    "            logger.warning(f\"No text content extracted from {file_path}\")\n",
    "            return []\n",
    "        \n",
    "        # Dividir texto en chunks (sin usar langchain)\n",
    "        chunks = chunk_text(text_content)\n",
    "        \n",
    "        # Generar UUIDs para los vectores\n",
    "        uuids = [str(uuid4()) for _ in range(len(chunks))]\n",
    "        \n",
    "        # Convertir chunks a vectores y subir a Pinecone\n",
    "        vectors_to_upsert = []\n",
    "        for chunk, doc_id in zip(chunks, uuids):\n",
    "            # Obtener embeddings\n",
    "            embedding = pinecone_helper.get_embeddings(chunk)\n",
    "            # Crear vector con metadata\n",
    "            vectors_to_upsert.append({\n",
    "                'id': doc_id,\n",
    "                'values': embedding,\n",
    "                'metadata': {\n",
    "                    **metadata,\n",
    "                    'text': chunk  # Agregar el texto como parte de metadata\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        if not vectors_to_upsert:\n",
    "            logger.warning(\"No vectors to upsert\")\n",
    "            return []\n",
    "        \n",
    "        # Subir vectores a Pinecone\n",
    "        logger.info(f\"Vectors to upsert: {len(vectors_to_upsert)}\")\n",
    "        \n",
    "        response = pinecone_helper.upsert_vectors(vectors_to_upsert)\n",
    "        logger.info(f\"Upsert successful. Response: {response}\")\n",
    "        \n",
    "        # Devolver IDs de los vectores\n",
    "        return uuids\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing document to Pinecone: {str(e)}\", exc_info=True)\n",
    "        return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_aje_library",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
